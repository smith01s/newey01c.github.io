---
layout: post
title: KPV Validation
comments: true
---

A KPV is a *Key Point Value*. From the [FlightDataAnalyzer][fda] docs:

> A Key Point Value is a value of interest measured at a point during a flight.
> The key attribute of a KPV is the value - which represents a measured value
> at a point in the flight.  A point can be a single instance or the start of a
> slice eg. duration.

<!-- more -->

In real terms, a KPV is an "interesting value" - usually sensor output that's
been saved in the flight data recorder, decoded using the appropriate LFL
definition[^lfl] each aircraft has a standard data format which is usually
unique to its particular model), and then converted to "engineering units" -
standard units of measurement. Usually a KPV is recorded at a *specific point
in the flight* (for example, during liftoff or approach/landing). However, note
that not all KPVs are directly calculated from sensor data - some are *derived*
from other KPVs (determined by applying some transfirmation). An example of
this is the transformation from total air temperature to static air temperature
(a transformation has to be applied based on the speed of the aircraft - to
account for temperature changes based on friction and compression of air).

[fda]: http://flightdataanalyzer.readthedocs.io/en/latest/KeyPointValue.html
[^lfl]: An LFL is a "Logical Frame Layout" - a standard data description format
    associated with the output of the flight data recorder for each particular
    model or variety of aircraft.

# Difficulties - Data Quality

This could potentially be a case of "too many cooks". Data analytics is quite
far removed from the initial recovery and processing of data - meaning that any
analysis is likely to be quite fragile because there are so many different
places that numerical errors can be introduced. Typically, errors are
introduced in the conversion from the data frame (i.e. data from the flight
data recorder) to engineering units. There are lots of different ways that
errors can be introduced, but essentially data is encoded when going into the
flight data recorder - often in non-standard ways that aren't always documented
correctly by the aircraft manufacturer - or that get misinterpreted by the data
frame developers (i.e. the people who write the frame layouts for decoding
data). As such, a sizeable proportion of errors (e.g. false positives for
events and so forth) come from this data decoding process.

## Basic Bounds Checking

Before applying any statistical validation to KPVs, it's helpful to remove as
much junk data as possible beforehand. In this case, it means that domain
knowledge should be harnessed to develop sensible heuristics to get rid of junk
data. For example, take the KPV `Pitch At Liftoff`. This is the angle of the
nose of the aircraft as it leaves the ground (specifically, as the radio
altimeter reads an altitude of greater than 0). For some flights, this KPV
registers a value of less than 0, which is obviously incorrect - the nose of
the aircraft is unlikely to be pointing *towards the ground* during takeoff
(unless this metric needs to be adjusted for the attack angle of the wings,
flaps, elevators, etc).

![An example of the Pitch At Liftoff KPV - note the yellow values on the
histogram.](/images/pitch_at_liftoff.svg)

This sort of process applies to many other KPVs, too - even these simple data
quality checks can catch a surprising amount of invalid data - or highlight
unusual patterns at least. For example, the negative `Pitch At Takeoff` value
could well generated by *helicopters* - which obviously, don't need to increase
pitch to climb!

## Correlation Analysis

Certain KPVs are likely to be correlated with each other - for example, SAT/TAT
and altitude. As altitude increases, temperature is expected to decrease
(specifically, by about 2 degrees Celsius per 1000ft). Clearly then, if
temperature is measured at several different altitudes during the flight, one
would expect to see a negative correlation between altitude and air
temperature.

Interestingly, if a particular flight doesn't exhibit this correlation pattern,
it is quite likely (barring any data conversion errors, of course) that the
aircraft experienced a temperature inversion (potentially creating challenging
conditions for the pilots).

## Monitoring Distributions Over Time

### Mean, Standard Deviation

Self explanatory - monitor standard distribution parameters over time (mean,
standard deviation, perhaps skew and kurtosis). Perhaps try to characterise
distribution types, as well (e.g. exponential/Weibull/Gaussian).

### Number of Modes (Unsupervised Cluster Analysis)

Generally, one would expect the number of modes in a distribution to remain
constant over time. Data generated in a similar manner should retain the same
distributional structure - particularly as each distribution is generally
unique to each aircraft model and aircraft type (i.e. helicopters and
aeroplanes). For examplle, note the plot below containing distributions of
`Pitch At Liftoff` - there is a strange bimodal structure for the A330 and
A340 - perhaps a scaling issue.

![An example of unimodal and bimodal
distributions](/images/pitch_at_liftoff_distributions.svg)

In the case of the A330 and A340 above displaying clear bimodal distributions,
it is potentially useful to apply a clustering algorithm to estimate (in an
unsupervised manner, at least) the number of clusters. In the case displayed
below, mean-shift clustering has been applied - each subsequent cluster has
been highlighted with its own colour.

![An example of mean-shift clustering applied to bimodal
data](/images/mean_shift_clustering.svg)

## Probabilistic Filtering Methods

To see how KPVs develop over time, it might be helpful to consider a
probabilistic modelling technique such as a Kalman filter. A Kalman filter
should be able to very quickly learn the normal variation of a time-series
dataset (e.g. monthly KPV data), and make probabilistic estimates of the bounds
that the data should lie within. Even more conveniently, this filtering
approach should be able to estimate sensible confidence bounds for parameter
values (as it is a Bayesian method) - and therefore, trigger sensible automated
alerts when this threshold is exceeded.
